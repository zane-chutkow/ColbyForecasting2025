[
  {
    "objectID": "C03_covariates.html",
    "href": "C03_covariates.html",
    "title": "Covariates",
    "section": "",
    "text": "“In the end that was the choice you made, and it doesn’t matter how hard it was to make it. It matters that you did.”\n\nCassandra Clare\nNow we turn our attention to what we know and guess about the environments. We are using the Brickman data to make habitat suitability maps for select species under two climate scenarios (RCP45 and RCP85) at two different times (2055 and 2075) in the future. Each variable we might use is called covariate or predictor. Our covariates are nicely packaged up and tidy, but the reality is that it often requires a good deal of data wrangling if the data are messy.\nOur step here is to make sure that two or more covariates are not highly correlated if they are, then we would likely want to drop all but one.",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C03_covariates.html#reading-in-the-covariates",
    "href": "C03_covariates.html#reading-in-the-covariates",
    "title": "Covariates",
    "section": "2.1 Reading in the covariates",
    "text": "2.1 Reading in the covariates\nWe’ll read in the Brickman database, then filter two different subsets to read: “STATIC” covariate bathymetry that apply across all scenarios and times and monthly covariates for the “PRESENT” period. Note that depth is automatically included - that’s an option - see ?read_brickman for more information.\n\ndb = brickman_database()\npresent = read_brickman(filter(db, scenario == \"PRESENT\", interval == \"mon\"))\n\nWe have used August before as our example, let’s continue with August.\n\naug = present |&gt;\n  dplyr::slice(\"month\", \"Aug\")",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C03_covariates.html#make-a-pairs-plot",
    "href": "C03_covariates.html#make-a-pairs-plot",
    "title": "Covariates",
    "section": "2.2 Make a pairs plot",
    "text": "2.2 Make a pairs plot\nA pairs plot is a plot often used in exploratory data analysis. It makes a grid of mini-plots of a set of variables, and reveals the relationships among the variables pair-by-pair. It’s easy to make.\n\npairs(aug)\n\n\n\n\n\n\n\n\nIn the lower left portion of the plot we see paired scatter plots, at upper right we see the correlation values of the pairs, and long the diagonal we see a histogram of each variable. Some pairs are highly correlated, say over 0.7, and to include both in the modeling might not provide us with greater predictive power. It may feel counterintuitive to remove any variables - more data means more information, right? And more information means more informed models. Consider two measurements, human arm length and inseam. We might use these to predict if a person is tall, but since they are probably strongly collinear/correlated do we really need both?",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C03_covariates.html#identify-the-most-independent-variables-and-the-most-collinear",
    "href": "C03_covariates.html#identify-the-most-independent-variables-and-the-most-collinear",
    "title": "Covariates",
    "section": "2.3 Identify the most independent variables (and the most collinear)",
    "text": "2.3 Identify the most independent variables (and the most collinear)\nWe have a function that can help use select which variables to remove. filter_collinear() returns a listing of variables it suggests we keep. It attaches to the return value an attribute (like a post-it note stuck on a box) that lists the complementary variables that it suggests we drop. We are choosing a particular method, but you can learn more about using R’s help for ?filter_collinear.\n\nkeep = filter_collinear(aug, method = \"vif_step\")\nkeep\n\n[1] \"MLD\"  \"Sbtm\" \"SSS\"  \"SST\"  \"Tbtm\" \"U\"    \"V\"   \nattr(,\"to_remove\")\n[1] \"Xbtm\"  \"depth\"\n\n\nOf course, we can decide to ignore this advice, and pick which ever ones we want including keeping them all.\nWhatever selection of variables we decide to model with, we will save this listing to a file. That way we can refer to it progammatically. But that comes later.",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C03_covariates.html#a-closer-look-at-the-model-input-data",
    "href": "C03_covariates.html#a-closer-look-at-the-model-input-data",
    "title": "Covariates",
    "section": "2.4 A closer look at the model input data",
    "text": "2.4 A closer look at the model input data\nBefore we do commit to a selection of variables, let’s turn our attention back to our presence-background points, and look at just those chosen values rather than at values drawn form across the entire domain. Let’s open the file that contains the “greedy” model input for August during the PRESENT climate scenario.\n\nmodel_input = read_model_input(scientificname = \"Mola mola\", \n                               approach = \"greedy\", \n                               mon = \"Aug\")\nmodel_input\n\nSimple feature collection with 7236 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -74.89169 ymin: 38.8678 xmax: -65.02004 ymax: 45.21401\nGeodetic CRS:  WGS 84\n# A tibble: 7,236 × 2\n   class                    geom\n   &lt;chr&gt;             &lt;POINT [°]&gt;\n 1 presence    (-72.8074 39.056)\n 2 presence      (-71.343 40.52)\n 3 presence  (-68.7691 41.52448)\n 4 presence       (-67.79 43.32)\n 5 presence (-68.44324 42.61177)\n 6 presence    (-72.4328 40.213)\n 7 presence   (-71.8784 40.3569)\n 8 presence      (-65.78 43.195)\n 9 presence       (-70.5 42.767)\n10 presence   (-72.3024 40.1862)\n# ℹ 7,226 more rows\n\n\nNext we’ll extract data values from our August covariates.\n\nvariables = extract_brickman(aug, model_input, form = \"wide\")\nvariables\n\n# A tibble: 7,236 × 10\n   point   MLD  Sbtm   SSS   SST  Tbtm         U         V     Xbtm depth\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;\n 1 p0001  5.17  35.0  31.6  23.3  7.50 -0.00161  -0.00340  0.00133  304. \n 2 p0002  4.25  32.8  30.6  21.6  8.15 -0.00420  -0.00206  0.00166   71.6\n 3 p0003  4.64  34.0  30.7  20.2  7.05  0.00168   0.00148  0.000793 138. \n 4 p0004  5.58  34.6  30.7  18.8  7.55  0.00267  -0.000410 0.000957 234. \n 5 p0005  5.04  34.7  30.7  19.0  7.43 -0.00619  -0.00121  0.00224  205. \n 6 p0006  4.01  32.4  30.6  22.0  8.22 -0.00344  -0.000859 0.00126   62.6\n 7 p0007  4.10  32.9  30.5  21.8  8.34 -0.00565  -0.00226  0.00216   71.3\n 8 p0008  3.82  32.4  30.3  18.2  3.56 -0.00702  -0.00431  0.00293   81.6\n 9 p0009  3.20  32.4  30.6  17.9  5.73  0.000275 -0.00101  0.000372  70.6\n10 p0010  4.02  32.9  30.6  22.0  8.62 -0.000900 -0.00148  0.000614  64.9\n# ℹ 7,226 more rows\n\n\nWe are going to call a plotting function, plot_pres_vs_bg(), that wants some of the data from model_input and some of the data in variables. So, we have to do some data wrangling to combine those; we’ll add class to variables and then drop the point column.\n\nvariables = variables |&gt;\n  mutate(class = model_input$class) |&gt;    # the $ extracts a column \n  select(-point)                          # the - means \"deselect\" or \"drop\"\nvariables\n\n# A tibble: 7,236 × 10\n     MLD  Sbtm   SSS   SST  Tbtm         U         V     Xbtm depth class   \n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;   \n 1  5.17  35.0  31.6  23.3  7.50 -0.00161  -0.00340  0.00133  304.  presence\n 2  4.25  32.8  30.6  21.6  8.15 -0.00420  -0.00206  0.00166   71.6 presence\n 3  4.64  34.0  30.7  20.2  7.05  0.00168   0.00148  0.000793 138.  presence\n 4  5.58  34.6  30.7  18.8  7.55  0.00267  -0.000410 0.000957 234.  presence\n 5  5.04  34.7  30.7  19.0  7.43 -0.00619  -0.00121  0.00224  205.  presence\n 6  4.01  32.4  30.6  22.0  8.22 -0.00344  -0.000859 0.00126   62.6 presence\n 7  4.10  32.9  30.5  21.8  8.34 -0.00565  -0.00226  0.00216   71.3 presence\n 8  3.82  32.4  30.3  18.2  3.56 -0.00702  -0.00431  0.00293   81.6 presence\n 9  3.20  32.4  30.6  17.9  5.73  0.000275 -0.00101  0.000372  70.6 presence\n10  4.02  32.9  30.6  22.0  8.62 -0.000900 -0.00148  0.000614  64.9 presence\n# ℹ 7,226 more rows\n\n\nFinally, can make a specialized plot comparing our variables for each class: presence and background.\n\nplot_pres_vs_bg(variables, \"class\")\n\n\n\n\n\n\n\n\nHow does this inform our thinking about reducing the number of variables? For which variables do presence and background values mirror each other? Which have the least overlap? We know that the model works by finding optimal combinations of covariates for the species. If there is never a difference between the conditions for presences and background then how will it find the optimal niche conditions?",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C03_covariates.html#saving-a-file-to-keep-track-of-modeling-choices",
    "href": "C03_covariates.html#saving-a-file-to-keep-track-of-modeling-choices",
    "title": "Covariates",
    "section": "2.5 Saving a file to keep track of modeling choices",
    "text": "2.5 Saving a file to keep track of modeling choices\nYou may have noticed that we write a lot of things to files (aka, “writing to disk”). It’s a useful practice especially when working with a multi-step process. One particular file, a configuration file, is used frequently in data science to store information about the choices we make as we work through our project. Configuration files generally are simple text files that we can easily get the computer to read and write.\nIn R, a confguration is treated as a named list. Each element of a list is named, but beyond that there aren’t any particular rules about confugurations. You can learn more about configurations in this tutorial.\nLet’s make a confuguration list that holds 4 items: version identifier, species name, sampling approach and the names of the variables to model with.\n\ncfg = list(\n  version = \"g_Aug\",               # g for greedy!\n  scientificname = \"Mola mola\",\n  approach = \"greedy\",\n  mon = \"Aug\",\n  keep_vars =  keep)\n\nWe can access by name three ways using what is called “indexing” : using the [[ indexing brackets, using the $ indexing operator or using the getElement() function.\n\ncfg[['scientificname']]\n\n[1] \"Mola mola\"\n\ncfg[[2]]\n\n[1] \"Mola mola\"\n\ncfg$scientificname\n\n[1] \"Mola mola\"\n\ngetElement(cfg, \"scientificname\")\n\n[1] \"Mola mola\"\n\ngetElement(cfg, 2)\n\n[1] \"Mola mola\"\n\n\nNow we’ll write this list to a file. First let’s set up a pathwy where we might store these configurations, and for that matter, to store our modeling files. We’ll make a new directory, models/g008 and write the configuration there. We’ll use the famous “YAML” format to store the file. See the file functions/configuration.R for documentation on reading and writing.\n\nok = make_path(data_path(\"models\")) # make a directory for models\nwrite_configuration(cfg)            \n\nUse the Files pane to navigate to your personal data directory. Open the g_Aug.yaml file - this is what you configuration looks like in YAML. Fortunately we don’t mess manually with these much.",
    "crumbs": [
      "Covariates"
    ]
  },
  {
    "objectID": "C04_models.html",
    "href": "C04_models.html",
    "title": "Models",
    "section": "",
    "text": "All models are wrong, but some are useful.\n\nGeorge Box\nModeling starts with a collection of observations (presence and background for us!) and ends up with a collection of coeefficients that can be used with one or more formulas to make a predicition for the past, the present or the future. We are using modeling specifically to make habitat suitability maps for select species under two climate scenarios (RCP45 and RCP85) at two different times (2055 and 2075) in the future.\nWe can choose from a number of different models: random forest “rf”, maximum entropy “maxent” or “maxnet”, boosted regression trees “brt”, general linear models “glm”, etc. The point of each is to make a mathematical representation of natural occurrences. It is important to consider what those occurences might be - categorical like labels? likelihoods like probabilities? continuous like measurements? Here are examples of each…\nWe are modeling with known observations (presences) and a sampling of the background, so we are trying to model a likelihood that a species will be encountered (and reported) relative to the environmental conditions. We are looking for a model that can produce relative likelihood of an encounter that results in a report.\nWe’ll be using a random forest model (rf). We were inspired to follow this route by using this tidy models tutorial prepared by our colleague Omi Johnson.",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#modifying-the-recipe-with-steps",
    "href": "C04_models.html#modifying-the-recipe-with-steps",
    "title": "Models",
    "section": "5.1 Modifying the recipe with steps",
    "text": "5.1 Modifying the recipe with steps\nSteps are cumulative modifications, and that means the order in which they are added matters. These steps comprise the bulk of pre-processing steps.\nSome modifications are applied row-by-row. For example, rows of the input modeling data that have one or more missing values (NAs) can be problematic and they should be removed.\nOther modifications are to manipulate entire columns. Sometimes the recipes requires subsequent steps before the modeling begins in earnest. For example we know from experience that it is often useful to log scale (base 10) depth when working with biological models. If depth and Xbtm have made it this far, you’ll note that each range over 4 or more orders of magnitude. That’s not a problem by itself, but it can introduce a bias toward larger values whenever the mean is computed. So, we’ll add a step for log scaling these, but only if depth and Xbtm have made it this far (this may vary by species.)\n\nrec = rec |&gt; \n  step_naomit()\nif (\"depth\" %in% cfg$keep_vars){\n  rec = rec |&gt;\n    step_log(depth,  base = 10)\n}\nif (\"Xbtm\" %in% cfg$keep_vars){\n  rec = rec |&gt;\n    step_log(Xbtm,  base = 10)\n}\nrec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 7\n\n\n\n\n\n── Operations \n\n\n• Removing rows with NA values in: &lt;none&gt;\n\n\nNext we state that we want to remove variables that might be highly correlated with other variables. If two variables are highly correlated, they will not provide the modeling system with more information, just redundant information which doesn’t neccessarily help. step_corr() accepts a variety of arguments specifying which variables to test to correlation including some convenience selectors like all_numeric(), all_string() and friends. We want all predictors which happen to all be numeric, so we can use all_predictors() or all_numeric_predictors(). Specificity is better then generality so let’s choose numeric predictors.\n\n\n\n\n\n\nNote\n\n\n\nWe have already tested variables for high collinearlity, but here we can add a slightly different filter, high correlation, for the same issue. Since we have dealt with this already we shouldn’t expect that step will change the preprocessing very much. But it is instructive to see it in action.\n\n\n\nrec = rec |&gt; \n  step_corr(all_numeric_predictors())\nrec\n\n\n\n\n── Recipe ──────────────────────────────────────────────────────────────────────\n\n\n\n\n\n── Inputs \n\n\nNumber of variables by role\n\n\noutcome:   1\npredictor: 7\n\n\n\n\n\n── Operations \n\n\n• Removing rows with NA values in: &lt;none&gt;\n\n\n• Correlation filter on: all_numeric_predictors()",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#add-the-recipe-to-the-workflow",
    "href": "C04_models.html#add-the-recipe-to-the-workflow",
    "title": "Models",
    "section": "5.2 Add the recipe to the workflow",
    "text": "5.2 Add the recipe to the workflow\n\nwflow = wflow |&gt;\n  add_recipe(rec)\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: None\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_naomit()\n• step_corr()",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#create-the-model",
    "href": "C04_models.html#create-the-model",
    "title": "Models",
    "section": "6.1 Create the model",
    "text": "6.1 Create the model\nWe create a random forest model, declare that it should be run in classification mode (not regression mode), and then specify that we want to use the ranger modeling engine (as opposed to, say, the randForest engine). We additionally specify that it should be able to produce probablilites of a class not just the class label. We also request that it saves bits of info so that we can compare the relative importance of the covariates.\n\nmodel = rand_forest() |&gt;\n  set_mode(\"classification\") |&gt;\n  set_engine(\"ranger\", probability = TRUE, importance = \"permutation\") \nmodel\n\nRandom Forest Model Specification (classification)\n\nEngine-Specific Arguments:\n  probability = TRUE\n  importance = permutation\n\nComputational engine: ranger \n\n\nWell, that feels underwhelming. We can pass arguments unique to the engine using the set_args() function, but, for now we’ll accept the defaults.",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#add-the-model-to-the-workflow",
    "href": "C04_models.html#add-the-model-to-the-workflow",
    "title": "Models",
    "section": "6.2 Add the model to the workflow",
    "text": "6.2 Add the model to the workflow\nNow we simply add the model to the workflow.\n\nwflow = wflow |&gt;\n  add_model(model)\nwflow\n\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_naomit()\n• step_corr()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (classification)\n\nEngine-Specific Arguments:\n  probability = TRUE\n  importance = permutation\n\nComputational engine: ranger",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#predict-with-the-training-data",
    "href": "C04_models.html#predict-with-the-training-data",
    "title": "Models",
    "section": "8.1 Predict with the training data",
    "text": "8.1 Predict with the training data\nFirst we shall predict with the same data we trained with. The results of this will not really tell us much about our model as it is very circular to predict using the very data used to build the model. So this next section is more about a first pass at using the tools at your disposal.\n\ntrain_pred = predict_table(fitted_wflow, tr_data, type = \"prob\")\ntrain_pred\n\n# A tibble: 5,426 × 4\n   .pred_presence .pred_background .pred      class     \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;     \n 1        0.00994            0.990 background background\n 2        0.00394            0.996 background background\n 3        0.0148             0.985 background background\n 4        0.372              0.628 background background\n 5        0.0592             0.941 background background\n 6        0.0260             0.974 background background\n 7        0.0443             0.956 background background\n 8        0.0382             0.962 background background\n 9        0.0262             0.974 background background\n10        0.0333             0.967 background background\n# ℹ 5,416 more rows\n\n\nHere the variables prepended with a dot . are computed, while the class variable is our original. There are many metrics we can use to determine how well this model predicts. Let’s start with the simplest thing… we can make a simply tally of .pred and class.\n\ncount(train_pred, .pred, class)\n\n# A tibble: 4 × 3\n  .pred      class          n\n  &lt;fct&gt;      &lt;fct&gt;      &lt;int&gt;\n1 presence   presence    1420\n2 presence   background   345\n3 background presence     417\n4 background background  3244\n\n\nThere false positives and false negatives, but many are correct. Of course, this is predicting with the very data we used to train the model; knowing that this is predicicting on training data with some many misses might not inspire confidence. But let’s explore more.",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#assess-the-model",
    "href": "C04_models.html#assess-the-model",
    "title": "Models",
    "section": "8.2 Assess the model",
    "text": "8.2 Assess the model\nHewre we walk through a number of common assessment tools. We want to assess a model to ascertain how closely it models reality (or not!) Using the tools is always easy, interpreting the metrics is not always easy.\n\n8.2.1 Confusion matrix\nThe confusion matrix is the next step beyond a simple tally that we made above.\n\ntrain_confmat = conf_mat(train_pred, class, .pred)\ntrain_confmat\n\n            Truth\nPrediction   presence background\n  presence       1420        345\n  background      417       3244\n\n\nYou’ll see this is the same as the simple tally we made, but it comes with handy plotting functionality (shown below). Note that a perfect model would have the upper left and lower right quadrants fully accounting for all points. The lower left quadrant shows us the number of false-negatives while the upper right quadrant shows the number of false-positives.\n\nautoplot(train_confmat, type = \"heatmap\")\n\n\n\n\n\n\n\n\n\n\n8.2.2 ROC and AUC\nThe area under the curve (AUC) of the receiver-operator curve (ROC) is a common metric. AUC values range form 0-1 with 1 reflecting a model that faithfully predicts correctly. Technically an AUC value of 0.5 represents a random model (yup, the result of a coin flip!), so values greater than 0.5 and less than 1.0 are expected.\nFirst we can plot the ROC.\n\nplot_roc(train_pred, class, .pred_presence)\n\n\n\n\n\n\n\n\nWe can assure you from practical experience that this is an atypical ROC. Typically they are not smooth, but this smoothness is an artifact of our use of training data. If you really only need the AUC, you can use the roc_auc() function directly.\n\nroc_auc(train_pred, class,  .pred_presence)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 roc_auc binary         0.945\n\n\n\n\n8.2.3 Accuracy\nAccuracy, much like our simple tally above, tells us what fraction of the predictions are correct. Not that here we explicitly provide the predicted class label (not the probability.)\n\naccuracy(train_pred, class, .pred)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.860\n\n\n\n\n8.2.4 Partial dependence plot\nPartial dependence reflects the relative contrubution of each variable influence over it’s full range of values. The output is a grid grid of plots showing the relative distribution of the variable (bars) as well as the relative influenceof the variable (line).\n\npartial_dependence_plot(fitted_wflow, data = tr_data)",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C04_models.html#predict-with-the-testing-data",
    "href": "C04_models.html#predict-with-the-testing-data",
    "title": "Models",
    "section": "8.3 Predict with the testing data",
    "text": "8.3 Predict with the testing data\nFinally, we can repeat these steps with the testing data. This should give use better information than using the training data\n\n8.3.1 Predict\n\ntest_data = testing(split_data)\ntest_pred = predict_table(fitted_wflow, test_data, type = \"prob\")\ntest_pred\n\n# A tibble: 1,810 × 4\n   .pred_presence .pred_background .pred      class   \n            &lt;dbl&gt;            &lt;dbl&gt; &lt;fct&gt;      &lt;fct&gt;   \n 1          0.469            0.531 background presence\n 2          0.733            0.267 presence   presence\n 3          0.732            0.268 presence   presence\n 4          0.592            0.408 presence   presence\n 5          0.259            0.741 background presence\n 6          0.851            0.149 presence   presence\n 7          0.588            0.412 presence   presence\n 8          0.703            0.297 presence   presence\n 9          0.566            0.434 presence   presence\n10          0.238            0.762 background presence\n# ℹ 1,800 more rows\n\n\n\n\n8.3.2 Confusion matrix\n\ntest_confmat = conf_mat(test_pred, class, .pred)\nautoplot(test_confmat, type = \"heatmap\")\n\n\n\n\n\n\n\n\n\n\n8.3.3 ROC/AUC\n\nplot_roc(test_pred, class, .pred_presence)\n\n\n\n\n\n\n\n\nThis ROC is more typical of what we see in regular practice.\n\n\n8.3.4 Accuracy\n\naccuracy(test_pred, class, .pred)\n\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy binary         0.685\n\n\n\n\n8.3.5 Partial Dependence\n\npartial_dependence_plot(fitted_wflow, data = test_data)",
    "crumbs": [
      "Models"
    ]
  },
  {
    "objectID": "C05_prediction.html",
    "href": "C05_prediction.html",
    "title": "Prediction",
    "section": "",
    "text": "It’s tough to make predictions, especially about the future.\n\nYogi Berra\nFinally we come to the end product of forecasting: the prediction. This last step is actually fairly simple, given a recipe and model (now bundled in a workflow container), run the same data-prep and predicting steps as we did earlier. One modification is that we now want to predict across the entire domain of our Brickman data set. You may recall that we are able to read these arrays, display them and extract point data from them. But we haven’t used them en mass as a variable yet.",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "C05_prediction.html#nowcast",
    "href": "C05_prediction.html#nowcast",
    "title": "Prediction",
    "section": "4.1 Nowcast",
    "text": "4.1 Nowcast\nFirst make the prediction. The function yields a stars array object that has three attributes: .pred_presence, .pred_background and .pred. The leading dot simply gives us the heads up that these three values are all computed. The first two range from 0-1 which implies a probability. The last, .pred, is the class label we would assign if we accept that any .pred_presence &gt;= 0.5 should be considered suitable habitat where a reported observation might occur.\n\nnowcast = predict_stars(wflow, covars)\nnowcast\n\nstars object with 2 dimensions and 3 attributes\nattribute(s):\n .pred_presence  .pred_background         .pred     \n Min.   :0.000   Min.   :0.001     presence  : 626  \n 1st Qu.:0.027   1st Qu.:0.761     background:5160  \n Median :0.092   Median :0.908     NA's      :4983  \n Mean   :0.179   Mean   :0.821                      \n 3rd Qu.:0.239   3rd Qu.:0.973                      \n Max.   :0.999   Max.   :1.000                      \n NA's   :4983    NA's   :4983                       \ndimension(s):\n  from  to offset    delta refsys point x/y\nx    1 121 -74.93  0.08226 WGS 84 FALSE [x]\ny    1  89  46.08 -0.08226 WGS 84 FALSE [y]\n\n\nNow we can plot what is often called a “habitat suitability index” (hsi) map.\n\ncoast = read_coastline()\nplot(nowcast['.pred_presence'], main = \"Nowcast August\", \n     axes = TRUE, breaks = seq(0, 1, by = 0.1), reset = FALSE)\nplot(coast, col = \"orange\", lwd = 2, add = TRUE)\n\n\n\n\n\n\n\n\nWe can also plot a presence/background labeled map, but keep in mind it is just a thresholded version of the above where “presence” means .pred_presence &gt;= 0.5.\n\nplot(nowcast['.pred'], main = \"Nowcast August Labels\", \n     axes = TRUE, reset = FALSE)\nplot(coast, col = \"black\", lwd = 2, add = TRUE)",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "C05_prediction.html#forecast",
    "href": "C05_prediction.html#forecast",
    "title": "Prediction",
    "section": "4.2 Forecast",
    "text": "4.2 Forecast\nNow let’s try our hand at forecasting - let’s try RCP85 in 2075. First we load those parameters, then run the prediction and plot.\n\ncovars_rcp85_2075 = read_brickman(db |&gt; filter(scenario == \"RCP85\", year == 2075, interval == \"mon\")) |&gt;\n  select(all_of(cfg$keep_vars)) |&gt;\n  slice(\"month\", \"Aug\") \n\n\nforecast_2075 = predict_stars(wflow, covars_rcp85_2075)\nforecast_2075\n\nstars object with 2 dimensions and 3 attributes\nattribute(s):\n .pred_presence  .pred_background         .pred     \n Min.   :0.000   Min.   :0.328     presence  :  33  \n 1st Qu.:0.155   1st Qu.:0.660     background:5753  \n Median :0.284   Median :0.716     NA's      :4983  \n Mean   :0.245   Mean   :0.755                      \n 3rd Qu.:0.340   3rd Qu.:0.845                      \n Max.   :0.672   Max.   :1.000                      \n NA's   :4983    NA's   :4983                       \ndimension(s):\n  from  to offset    delta refsys point x/y\nx    1 121 -74.93  0.08226 WGS 84 FALSE [x]\ny    1  89  46.08 -0.08226 WGS 84 FALSE [y]\n\n\n\ncoast = read_coastline()\nplot(forecast_2075['.pred_presence'], main = \"RCP85 2075 August\", \n     axes = TRUE, breaks = seq(0, 1, by = 0.1), reset = FALSE)\nplot(coast, col = \"orange\", lwd = 2, add = TRUE)\n\n\n\n\n\n\n\n\nHmmm, that’s pretty different than what the nowcast predicts.",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "C05_prediction.html#forecast-2055",
    "href": "C05_prediction.html#forecast-2055",
    "title": "Prediction",
    "section": "5.1 Forecast 2055",
    "text": "5.1 Forecast 2055\n\ncovars_rcp85_2055 = read_brickman(db |&gt; filter(scenario == \"RCP85\", year == 2055, interval == \"mon\")) |&gt;\n  select(all_of(cfg$keep_vars)) |&gt;\n  slice(\"month\", \"Aug\") \nforecast_2055 = predict_stars(wflow, covars_rcp85_2055)\nforecast_2055\n\nstars object with 2 dimensions and 3 attributes\nattribute(s):\n .pred_presence  .pred_background         .pred     \n Min.   :0.000   Min.   :0.447     presence  :  11  \n 1st Qu.:0.148   1st Qu.:0.662     background:5775  \n Median :0.277   Median :0.723     NA's      :4983  \n Mean   :0.242   Mean   :0.758                      \n 3rd Qu.:0.338   3rd Qu.:0.852                      \n Max.   :0.553   Max.   :1.000                      \n NA's   :4983    NA's   :4983                       \ndimension(s):\n  from  to offset    delta refsys point x/y\nx    1 121 -74.93  0.08226 WGS 84 FALSE [x]\ny    1  89  46.08 -0.08226 WGS 84 FALSE [y]",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "C05_prediction.html#bind-time-series",
    "href": "C05_prediction.html#bind-time-series",
    "title": "Prediction",
    "section": "5.2 Bind time series",
    "text": "5.2 Bind time series\nWe want to bind the .pred_presence attribute for each of the predictions (nowcast, forecast_2055 and forecast_2075). Let’s assume the “present” mean 2020 so we can assign a year.\n\nrcp85 = c(nowcast, forecast_2055, forecast_2075, along = list(year = c(\"2020\", \"2055\", \"2075\")))\n\n\n\n\n\n\n\nNote\n\n\n\nCurious about we provide year as a vector of characters instead of a vector of integers? Try running the command above again and check out the 3rd dimension.\n\n\nSince we are plotting multiple arrays, we need to plot the coastline using a “hook” function.\n\nplot_coast = function(){\n  plot(coast, col = \"orange\", lwd = 2, add = TRUE)\n}\n\nplot(rcp85['.pred_presence'], \n     hook = plot_coast,\n     axes = TRUE, breaks = seq(0, 1, by = 0.1), join_zlim  = TRUE, reset = FALSE)\n\n\n\n\n\n\n\n\nHmmmm. Why does there seem to be a strong shift between 2020 and 2055, while the 2055 to 2075 shift seems less pronounced?\n\n\n\n\n\n\nNote\n\n\n\nDon’t forget that there are other ways to plot array based spatial data.",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "C05_prediction.html#save-the-predictions",
    "href": "C05_prediction.html#save-the-predictions",
    "title": "Prediction",
    "section": "5.3 Save the predictions",
    "text": "5.3 Save the predictions\nWe could save all three attributes, but .pred_background is just 1 - .pred_presence, and .pred is just coding “presence” where .pred_presence &gt;= 0.5, so we can always compute those as needed if we have .pred_presence. In that case, let’s just save the first attribute, .pred_presence, in a multilayer GeoTIFF formatted image array file. The write_prediction() function will do just that.\n\n# make sure the output directory exists\npath = data_path(\"predictions\")\nif (!dir.exists(path)) ok = dir.create(path, recursive = TRUE)\n\n# write individual arrays?\nwrite_prediction(nowcast, file = file.path(path,\"g_Aug_RCP85_2020.tif\"))\nwrite_prediction(forecast_2055, file = file.path(path, \"g_Aug_RCP85_2055.tif\"))\nwrite_prediction(forecast_2075, file = file.path(path, \"g_Aug_RCP85_2075.tif\"))\n\n# or write them together in a \"multi-layer\" file?\nwrite_prediction(rcp85, file = file.path(path, \"g_Aug_RCP85_all.tif\"))\n\nTo read it back simply provide the filename to read_prediction(). If you are reading back a multi-layer array, be sure to check out the time argument to assign values to the time dimension. Single layer arrays don’t have the concept of time so the time argument is ignored.",
    "crumbs": [
      "Prediction"
    ]
  },
  {
    "objectID": "S01_observations.html",
    "href": "S01_observations.html",
    "title": "Lobster Observations",
    "section": "",
    "text": "Follow this wiki page on obtaining data from OBIS. Keep in mind that you will probably want a species with sufficient number of records in the northwest Atlantic. Just what constitutes “sufficient” is probably subject to some debate, but a couple of hundred as a minumum will be helpful for learning. One thing that might help is to be on alert species that are only congregate in one area such as right along the shoreline or only appear in a few months of the year. It isn’t that those species are not worthy of study, but they may make the learning process harder.\nYou should feel free to get the data for a couple of different species, if one becomes a headache with our given resources, then you can switch easily to another.",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#basisofrecord",
    "href": "S01_observations.html#basisofrecord",
    "title": "Lobster Observations",
    "section": "5.1 basisOfRecord",
    "text": "5.1 basisOfRecord\nNext we should examine the basisOfRecord variable to get an understanding of how these observations were made.\n\nobs |&gt; count(basisOfRecord)\n\nSimple feature collection with 5 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -74.9 ymin: 38.8 xmax: -65 ymax: 45.5\nGeodetic CRS:  WGS 84\n# A tibble: 5 × 3\n  basisOfRecord               n                                             geom\n* &lt;chr&gt;                   &lt;int&gt;                                   &lt;GEOMETRY [°]&gt;\n1 HumanObservation       192812 MULTIPOINT ((-65.15383 42.60283), (-65.1 42.583…\n2 LivingSpecimen            279 MULTIPOINT ((-66.02262 45.21849), (-66.0195 45.…\n3 NomenclaturalChecklist      1                       POINT (-65.80602 44.97985)\n4 Occurrence              15768 MULTIPOINT ((-65.1067 42.5198), (-65.0605 42.41…\n5 PreservedSpecimen         234 MULTIPOINT ((-65.4833 42.55), (-65.4833 42.7666…\n\n\nIf you are using a different species you may have different values for basisOfRecord. Let’s take a closer look at the complete records for one from each group.\n\nhuman = obs |&gt;\n  filter(basisOfRecord == \"HumanObservation\") |&gt;\n  slice(1) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/0000b941-cad3-4707-9b66-2fa77ba732b5\n\npreserved = obs |&gt;\n  filter(basisOfRecord == \"PreservedSpecimen\") |&gt;\n  slice(1) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/0052dbeb-3b38-4eb7-b708-e85ad1cb2acc\n\nchecklist = obs |&gt;\n  filter(basisOfRecord == \"NomenclaturalChecklist\") |&gt;\n  slice(1) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/2aec82a6-e10b-41f5-8209-d5e42565ca9a\n\noccurrence = obs |&gt;\n  filter(basisOfRecord == \"Occurrence\") |&gt;\n  slice(1) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/0000f8c7-eef7-4cd9-9847-8424a5ff5752\n\n\nNext let’s think about what our minimum requirements might be in oirder to build a model. To answer that we need to think about our environmental covariates in the Brickman data](https://github.com/BigelowLab/ColbyForecasting2025/wiki/Brickman). That data has dimensions of x (longitude), y (latitude) and month. In order to match obseravtions with that data, our observations must be complete in those three variables. Let’s take a look at a summary of the observations which will indicate the number of elements missing in each variable.\n\nsummary(obs)\n\n      id            basisOfRecord        eventDate               year      \n Length:209094      Length:209094      Min.   :1874-07-20   Min.   :1874   \n Class :character   Class :character   1st Qu.:2005-12-08   1st Qu.:2005   \n Mode  :character   Mode  :character   Median :2009-05-16   Median :2009   \n                                       Mean   :2008-04-27   Mean   :2008   \n                                       3rd Qu.:2013-05-10   3rd Qu.:2013   \n                                       Max.   :2022-09-14   Max.   :2022   \n                                       NA's   :39288        NA's   :39288  \n    month            eventTime         individualCount              geom       \n Length:209094      Length:209094      Min.   :   1.00   POINT        :209094  \n Class :character   Class :character   1st Qu.:   2.00   epsg:4326    :     0  \n Mode  :character   Mode  :character   Median :   6.00   +proj=long...:     0  \n                                       Mean   :  15.02                         \n                                       3rd Qu.:  15.00                         \n                                       Max.   :2308.00                         \n                                       NA's   :59204",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#eventdate",
    "href": "S01_observations.html#eventdate",
    "title": "Lobster Observations",
    "section": "5.2 eventDate",
    "text": "5.2 eventDate\nFor Mola mola there are some rows where eventDate is NA. We need to filter those. The filter function looks for a vector of TRUE/FALSE values - one for each row. In our case, we test the eventDate column to see if it is NA, but then we reverse the TRUE/FALSE logical with the preceding ! (pronounded “bang!”). This we retain only the rows where eventDate is notNA`, and then we print the summary again.\n\nobs = obs |&gt;\n  filter(!is.na(eventDate))\nsummary(obs)\n\n      id            basisOfRecord        eventDate               year     \n Length:169806      Length:169806      Min.   :1874-07-20   Min.   :1874  \n Class :character   Class :character   1st Qu.:2005-12-08   1st Qu.:2005  \n Mode  :character   Mode  :character   Median :2009-05-16   Median :2009  \n                                       Mean   :2008-04-27   Mean   :2008  \n                                       3rd Qu.:2013-05-10   3rd Qu.:2013  \n                                       Max.   :2022-09-14   Max.   :2022  \n                                                                          \n    month            eventTime         individualCount              geom       \n Length:169806      Length:169806      Min.   :   1.00   POINT        :169806  \n Class :character   Class :character   1st Qu.:   2.00   epsg:4326    :     0  \n Mode  :character   Mode  :character   Median :   6.00   +proj=long...:     0  \n                                       Mean   :  15.18                         \n                                       3rd Qu.:  15.00                         \n                                       Max.   :2308.00                         \n                                       NA's   :59154",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#individualcount",
    "href": "S01_observations.html#individualcount",
    "title": "Lobster Observations",
    "section": "5.3 individualCount",
    "text": "5.3 individualCount\nThat’s better, but we still have 315 NA values for individualCount. Let’s look at at least one record of those in detail; filter out one, and browse it.\n\nobs |&gt;\n  filter(is.na(individualCount)) |&gt;\n  slice(1) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/0000def7-0a89-4412-be90-50e3549d8434\n\n\nEeek! It’s a carcas that washed up on shore! We checked a number of others, and they are all carcases. Is that a presence? Is that what we model are modeling? If not then we should filer those out.\n\nobs = obs |&gt;\n  filter(!is.na(individualCount))\nsummary(obs)\n\n      id            basisOfRecord        eventDate               year     \n Length:110652      Length:110652      Min.   :1874-07-20   Min.   :1874  \n Class :character   Class :character   1st Qu.:2005-05-13   1st Qu.:2005  \n Mode  :character   Mode  :character   Median :2007-12-21   Median :2007  \n                                       Mean   :2006-10-15   Mean   :2006  \n                                       3rd Qu.:2011-01-06   3rd Qu.:2011  \n                                       Max.   :2014-12-31   Max.   :2014  \n    month            eventTime         individualCount              geom       \n Length:110652      Length:110652      Min.   :   1.00   POINT        :110652  \n Class :character   Class :character   1st Qu.:   2.00   epsg:4326    :     0  \n Mode  :character   Mode  :character   Median :   6.00   +proj=long...:     0  \n                                       Mean   :  15.18                         \n                                       3rd Qu.:  15.00                         \n                                       Max.   :2308.00                         \n\n\nWell now one has to wonder about a single observation of 25 animals. Let’s check that out.\n\nobs |&gt;\n  filter(individualCount == 25) |&gt;\n  browse_obis()\n\nPlease point your browser to the following url: \n\n\nhttps://api.obis.org/v3/occurrence/00f995dd-ffc0-4e97-aa54-ffc202495cae\n\n\nOK, that seems legitmate. And it is possible, Mola mola can congregate for feeding, mating and possibly for karaoke parties.",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#year",
    "href": "S01_observations.html#year",
    "title": "Lobster Observations",
    "section": "5.4 year",
    "text": "5.4 year\nWe know that the “current” climate scenario for the Brickman model data define “current” as the 1982-2013 window. It’s just an average, and if you have values from 1970 to the current year, you probably are safe in including them. But do your observations fall into those years? Let’s make a plot of the counts per year, with dashed lines shown the Brickman “current” cliamtology period.\n\nggplot(data = obs,\n       mapping = aes(x = year)) + \n  geom_bar() + \n  geom_vline(xintercept = c(1982, 2013), linetype = \"dashed\") + \n  labs(title = \"Counts per year\")\n\n\n\n\n\n\n\n\nFor this species, it seem like it is only the record from 1932 that might be a stretch, so let’s filter that out by rejecting records before 1970. This time, instead of asking for a summary, we’ll print the dimensions (rows, columns) of the table.\n\nobs = obs |&gt;\n  filter(year &gt;= 1970)\ndim(obs)\n\n[1] 109783      8\n\n\nThat’s still a lot of records. Now let’s check out the distribution across the months of the year.",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#month",
    "href": "S01_observations.html#month",
    "title": "Lobster Observations",
    "section": "5.5 month",
    "text": "5.5 month\nWe will be making models and predictions for each month of the for the 4 future projection climates. Species and observers do show some seasonality, but it that seasonality so extreme that it might be impossible to model some months because of sparse data? Let’s make a plot of the counts per month.\n\nggplot(data = obs,\n       mapping = aes(x = month)) + \n  geom_bar() + \n  labs(title = \"Counts per month\")\n\n\n\n\n\n\n\n\nOh, rats! By default ggplot plots in alpha-numeric order, which scrambles our month order. To fix that we have to convert the month in a factor type while specifying the order of the factors, and we’ll use the mutate() function to help us.\n\nobs = obs |&gt;\n  mutate(month = factor(month, levels = month.abb))\n\nggplot(data = obs,\n       mapping = aes(x = month)) + \n  geom_bar() + \n  labs(title = \"Counts per month\")\n\n\n\n\n\n\n\n\nThat’s better! So, it may be the for Mola mola we might not be able to successfully model in the cold winter months. That’s good to keep in mind.",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S01_observations.html#geometry",
    "href": "S01_observations.html#geometry",
    "title": "Lobster Observations",
    "section": "5.6 geometry",
    "text": "5.6 geometry\nLast, but certainly not least, we should consider the possibility that some observations might be on shore. It happens! We already know that some records included fish that were washed up on shore. It’s possible someone mis-keyed the longitude or latitude when entering the vaklues into the database. It’s alos possible that some observations fall just outside the areas where the Brickman data has values. To look for these points, we’ll load the Brickman mask (defines land vs water. Well, really it defines data vs no-data), and use that for further filtering.\nWe need to load the Brickman database, and then filter it for the static variable called “mask”.\n\ndb = brickman_database() |&gt;\n  filter(scenario == \"STATIC\", var == \"mask\")\nmask = read_brickman(db, add_depth = FALSE)\nmask\n\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n      Min. 1st Qu. Median Mean 3rd Qu. Max. NA's\nmask     1       1      1    1       1    1 4983\ndimension(s):\n  from  to offset    delta refsys point x/y\nx    1 121 -74.93  0.08226 WGS 84 FALSE [x]\ny    1  89  46.08 -0.08226 WGS 84 FALSE [y]\n\n\nLet’s see what our mask looks like with the observations drizzled on top. Because the mask only has values of 1 (data) or NA (no-data). You’ll note that we only want to plot the locations of the observations, so we strip obs of everyhting except its geometery.\n\nplot(mask, breaks = \"equal\", axes = TRUE, reset = FALSE)\nplot(st_geometry(obs), pch = \".\", add = TRUE)\n\n\n\n\n\n\n\n\nMaybe with proper with squinting we can see some that faal into no-data areas. The sure-fire way to tell is to extract the mask values at the point locations.\n\nhitOrMiss = extract_brickman(mask, obs)\nhitOrMiss\n\n# A tibble: 109,783 × 3\n   point   name  value\n   &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;\n 1 p000001 mask      1\n 2 p000002 mask      1\n 3 p000003 mask      1\n 4 p000004 mask      1\n 5 p000005 mask      1\n 6 p000006 mask      1\n 7 p000007 mask      1\n 8 p000008 mask      1\n 9 p000009 mask      1\n10 p000010 mask      1\n# ℹ 109,773 more rows\n\n\nOK, let’s tally the “value” variable.\n\ncount(hitOrMiss, value)\n\n# A tibble: 2 × 2\n  value      n\n  &lt;dbl&gt;  &lt;int&gt;\n1     1 104626\n2    NA   5157\n\n\nOoooo, 33 records in obs don’t line up with values in the mask (or in any Brickman data). We should filter those out; we’ll do so with a filter(). Note that we a “reaching” into the hitOrMiss table to access the value column when we use this hitOrMiss$value. Let’s figure out how many records we have dropped with all of this filtering.\n\nobs = obs |&gt;\n  filter(!is.na(hitOrMiss$value))\ndim_end = dim(obs)\n\ndropped_records = dim_start[1] - dim_end[1]\ndropped_records\n\n[1] 104468\n\n\nSo, we dropped 104468 records which is about 50.0% of the raw OBIS data. Is it worth all that to drop just 4% of the data? Yes! Models are like all things computer… if you put garbage in you should expect to get garbage back out.",
    "crumbs": [
      "Lobster_observations"
    ]
  },
  {
    "objectID": "S02_background.html",
    "href": "S02_background.html",
    "title": "Lobster Background",
    "section": "",
    "text": "Traditional ecological surveys are systematic, for a given species survey data sets tell us where the species is found and where it is absent. Using an observational data (like OBIS) set we only know where the species is found, which leaves us guessing about where they might not be found. This difference is what distinguishes a presence-abscence data set from a presence-only data set, and this difference guides the modeling process.\nWhen we model, we are trying to define the environs where we should expect to find a species as well as the environs we would not expect to find a species. We have in hand the locations of observations, and we can extract the environmental data at those locations. But to characterize the less suitable environments we are going to have to sample what is called “background”. We want these background samples to roughly match the regional preferences of the observations; that is we want to avoid having observations that are mostly over Georges Bank while our background samples are primarily around the Bay of Fundy.",
    "crumbs": [
      "Lobsert_Background"
    ]
  },
  {
    "objectID": "S02_background.html#sample-background",
    "href": "S02_background.html#sample-background",
    "title": "Lobster Background",
    "section": "2.1 Sample background",
    "text": "2.1 Sample background\nWhen we sample the background, we are creating the input for the model if we request that the observations (presences) are joined with the background.\nNext we sample the background as guided by the density map. We’ll ask for 2x as many presences, but it is just a request. We also request that no background point be further than 30km (30000m) from it’s closest presence point.\n\ngreedy_input = sample_background(obs, mask, \n                              n = 2 * nrow(obs),\n                              class_label = \"background\",\n                              method = c(\"dist_max\", 30000),\n                              return_pres = TRUE)\n\nWarning in sample_background(obs, mask, n = 2 * nrow(obs), class_label = \"background\", : There are fewer available cells for raster 'NA' (25629 presences) than the requested 51258 background points. Only 1034 will be returned.\n\ngreedy_input\n\nSimple feature collection with 26663 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -70.61397 ymin: 41.26535 xmax: -65 ymax: 45.54306\nGeodetic CRS:  WGS 84\n# A tibble: 26,663 × 2\n   class          geometry\n * &lt;fct&gt;       &lt;POINT [°]&gt;\n 1 presence (-65.44 43.45)\n 2 presence (-65.15 43.65)\n 3 presence (-65.15 43.65)\n 4 presence (-66.05 43.23)\n 5 presence (-66.15 44.26)\n 6 presence (-65.85 43.26)\n 7 presence  (-65.7 43.38)\n 8 presence (-65.22 43.64)\n 9 presence (-65.06 43.63)\n10 presence (-65.71 43.42)\n# ℹ 26,653 more rows\n\n\nYou may encounter a warning message that says, “There are fewer available cells for raster…”. This is useful information, there simply weren’t a lot of non-NA cells to sample from. Let’s plot this.\n\nplot(greedy_input['class'], \n     axes = TRUE,  \n     pch = \".\", \n     extent = mask, \n     main = \"December greedy class distribution\",\n     reset = FALSE)\nplot(coast, col = \"orange\", add = TRUE)\n\n\n\n\n\n\n\n\nHmmm, let’s tally the class labels.\n\ncount(greedy_input, class)\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -70.61397 ymin: 41.26535 xmax: -65 ymax: 45.54306\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 3\n  class          n                                                      geometry\n* &lt;fct&gt;      &lt;int&gt;                                              &lt;MULTIPOINT [°]&gt;\n1 presence   25629 ((-65.19 43.26), (-65.4 43.37), (-65.39 43.39), (-65.38 43.3…\n2 background  1034 ((-65.59588 42.66383), (-65.51362 42.74609), (-65.26683 42.7…\n\n\nWell, that’s imbalanced with a different number presences than background points. But, on the bright side, the background points are definitely in the region of observations.",
    "crumbs": [
      "Lobsert_Background"
    ]
  },
  {
    "objectID": "S02_background.html#thin-by-cell",
    "href": "S02_background.html#thin-by-cell",
    "title": "Lobster Background",
    "section": "3.1 Thin by cell",
    "text": "3.1 Thin by cell\nIn this approach we eliminate (thin) presences so that we have no more than one per covariate array cell.\n\ndim_before = dim(obs)\ncat(\"number of rows before cell thinning:\", dim_before[1], \"\\n\")\n\nnumber of rows before cell thinning: 25629 \n\nthinned_obs = thin_by_cell(obs, mask)\ndim_after = dim(thinned_obs)\ncat(\"number of rows after cell thinning:\", dim_after[1], \"\\n\")\n\nnumber of rows after cell thinning: 179 \n\n\nSo, that dropped quite a few!",
    "crumbs": [
      "Lobsert_Background"
    ]
  },
  {
    "objectID": "S02_background.html#make-a-weighted-sampling-map",
    "href": "S02_background.html#make-a-weighted-sampling-map",
    "title": "Lobster Background",
    "section": "3.2 Make a weighted sampling map",
    "text": "3.2 Make a weighted sampling map\nThere is a technique we can use to to make a weighted sampling map. Simply counting the number of original observations per cell will indicate where we are most likely to oberve Mola mola.\n\nsamp_weight = rasterize_point_density(obs, mask)\nplot(samp_weight, axes = TRUE, breaks = \"equal\", col = rev(hcl.colors(10)), reset = FALSE)\nplot(coast, col = \"orange\", lwd = 2, add = TRUE)\n\n\n\n\n\n\n\n\nNow let’s take a look at the background, but this time we’ll try to match the count of presences.\n\nconservative_input = sample_background(thinned_obs, samp_weight, \n                              n = 2 * nrow(thinned_obs),\n                              class_label = \"background\",\n                              method = \"bias\",\n                              return_pres = TRUE)\n\nWarning in sample_background(thinned_obs, samp_weight, n = 2 * nrow(thinned_obs), : There are fewer available cells for raster 'NA' (179 presences) than the requested 358 background points. Only 179 will be returned.\n\ncount(conservative_input, class)\n\nSimple feature collection with 2 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: -70.28492 ymin: 41.51214 xmax: -65 ymax: 45.4608\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 3\n  class          n                                                      geometry\n* &lt;fct&gt;      &lt;int&gt;                                              &lt;MULTIPOINT [°]&gt;\n1 presence     179 ((-65.19 43.26), (-65.39 43.39), (-65.29 43.4), (-65.37 43.4…\n2 background   179 ((-65.18456 43.23968), (-65.51362 43.23968), (-65.26683 43.4…\n\n\nWhoa - that’s many fewer background points.\n\nplot(conservative_input['class'], \n     axes = TRUE,  \n     pch = \".\", \n     extent = mask, \n     main = \"August conservative class distribution\",\n     reset = FALSE)\nplot(coast, col = \"orange\", add = TRUE)\n\n\n\n\n\n\n\n\nIt appears that background points are essentially shadowing the thinned presence points.",
    "crumbs": [
      "Lobsert_Background"
    ]
  },
  {
    "objectID": "S02_background.html#a-function-we-can-reuse",
    "href": "S02_background.html#a-function-we-can-reuse",
    "title": "Lobster Background",
    "section": "5.1 A function we can reuse",
    "text": "5.1 A function we can reuse\nHere we make a function that needs at least three arguments: the complete set of observations, the mask used for sampling (and possibly thinning) and the month to filter the observations. The pseudo-code might look like this…\nfor a given month\n  filter the obs for that month\n  make the greedy model input by sampling the background\n    save the greedy model input\n  thin the obs\n  make the conservative model input by sampling background\n    save the conservative model input\n  return a list the greedy and conservative model inputs\nPhew! That’s a lot of steps. To manually run those steps 12 times would be tedious, so we roll that into a function that we can reuse 12 times instead.\nThis function will have a name, make_model_input_by_month. It’s a long name, but it makes it obvious what it does. First we start with the documentation.\n\n#' Builds greedy and conservative model input data sets for a given month\n#' \n#' @param mon chr the month abbreviation for the month of interest (\"Jan\" by default)\n#' @param obs table, the complete observation data set\n#' @param raster stars, the object that defines the sampling space, usually a mask\n#' @param species chr, the name of the species prepended to the name of the output files.\n#'   (By default \"Mola mola\" which gets converted to \"Mola_mola\")\n#' @param path the output data path to store this data (be default \"model_input\")\n#' @param min_obs num this sets a threshold below which we wont try to make a model. (Default is 3)\n#' @return a named two element list of greedy and conservative model inputs - they are tables\nmake_model_input_by_month  = function(mon = \"Jan\",\n                                      obs = read_observations(\"Homarus americanus\"),\n                                      raster = NULL,\n                                      species = \"Homarus americanus\",\n                                      path = data_path(\"model_input\"),\n                                      min_obs = 3){\n  # the user *must* provide a raster\n  if (is.null(raster)) stop(\"please provide a raster\")\n  # filter the obs\n  obs = obs |&gt;\n    filter(month == mon[1])\n  \n  # check that we have at least some records, if not enough then alert the user\n  # and return NULL\n  if (nrow(obs) &lt; min_obs){\n    warning(\"sorry, this month has too few records: \", mon)\n    return(NULL)\n  }\n  \n  # make sure the output path exists, if not, make it\n  make_path(path)\n  \n  \n  # make the greedy model input by sampling the background\n  greedy_input = sample_background(obs, raster,\n                                   n = 2 * nrow(obs),\n                                   class_label = \"background\",\n                                   method = c(\"dist_max\", 30000),\n                                   return_pres = TRUE)\n  # save the greedy data\n  filename = sprintf(\"%s-%s-greedy_input.gpkg\", \n                     gsub(\" \", \"_\", species),\n                     mon)\n  write_sf(greedy_input, file.path(path, filename))\n  \n  # thin the obs\n  thinned_obs = thin_by_cell(obs, raster)\n  \n  # sampling weight\n  samp_weight = rasterize_point_density(obs, raster)\n  \n  # make the conservative model\n  conservative_input = sample_background(thinned_obs, samp_weight,\n                                   n = 2 * nrow(thinned_obs),\n                                   class_label = \"background\",\n                                   method = \"bias\",\n                                   return_pres = TRUE)\n  \n  # save the conservative data\n  filename = sprintf(\"%s-%s-conservative_input.gpkg\", \n                     gsub(\" \", \"_\", species),\n                     mon)\n  write_sf(conservative_input, file.path(path,filename))\n  \n  # make a list\n  r = list(greedy = greedy_input, conservative = conservative_input)\n  \n  # return, but disable automatic printing\n  invisible(r)\n  \n}",
    "crumbs": [
      "Lobsert_Background"
    ]
  }
]